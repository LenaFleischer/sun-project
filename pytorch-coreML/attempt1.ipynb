{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e883aeb-2d05-4ab3-bf99-dc438c57e45e",
   "metadata": {},
   "source": [
    "### PYTORCH TO COREML\n",
    "using the same basic windchill prediction model, training and trying to deploy in coreml\n",
    "https://coremltools.readme.io/docs/pytorch-conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0a4c2de-fa80-492f-80e3-a596d53c09ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lena/opt/anaconda3/envs/sunproject/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e401610-e7e0-455c-a01a-bb66cf3a7af4",
   "metadata": {},
   "source": [
    "- load in weather data using only valid columns, leaving out the last column (wind chill label)\n",
    "- create a tensor from all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "538e3a05-f287-424b-8e03-1b38b85cd29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = np.genfromtxt(\"2022_data.csv\",delimiter = \",\", usecols = (0,1,2,3,4,6,8,9,11,12,15,17,18,19,22), skip_header = 1, filling_values=0.0)[:, :-1]\n",
    "weather_tensor = torch.tensor(weather_data).float()\n",
    "xdims = weather_tensor.shape[1] - 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b205802-ebfc-409a-839b-dbc9424cbe75",
   "metadata": {},
   "source": [
    "Make a pytorch DataSet from the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49ac3b65-2497-4fbc-a4f6-aad811409303",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_dataset = torch.utils.data.TensorDataset(weather_tensor[:, :-1], weather_tensor[:, -1:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5b1d70-e950-428d-bdbd-ef5b2a22c887",
   "metadata": {},
   "source": [
    "DataLoader \n",
    "puts data on the right device, shuffles, can use parallel programming, define batch size etc\n",
    "- sees everything in an epoch\n",
    "- next epoch, sees them in a different order\n",
    "- suffles with 32 irows in a batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6de71f8a-05a3-4e19-a9a4-f4ba504270a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(weather_dataset, shuffle=True, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39b23c8f-3eca-446b-8552-f8e356af67da",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(xdims, 32), # takes in x dims columns, then funnels to a hidden layer of 32\n",
    "    torch.nn.ELU(), \n",
    "    # ELU is an activation layer, like a sigmoidal function!\n",
    "    torch.nn.Linear(32, 32),\n",
    "    torch.nn.ELU(),\n",
    "    torch.nn.Linear(32, 16),\n",
    "    torch.nn.ELU(),\n",
    "    torch.nn.Linear(16, 1)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be37741a-cc84-4a16-9ce6-22ca49ec2f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean squared error loss function\n",
    "criterion = torch.nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53e282f5-1a01-443e-9165-3636340cd247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer called Adam, using a learning rate of 1e-4\n",
    "opt = torch.optim.Adam(net.parameters(), 1e-4 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb0eda7-d98d-4a91-931a-34fa1a40e8db",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f373687-a0f6-4876-9bdb-93eeb08e8205",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for ep in range(1000):\n",
    "    # every epoch sees every row exactly one time, but inputs are shuffled every epoch\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    # batch by batch\n",
    "    for batch in loader:\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        \n",
    "        batchX = batch[0]\n",
    "        batchY = batch[1]\n",
    "\n",
    "        pred = net(batchX)\n",
    "        loss = criterion(pred, batchY)\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d7ed24d-35fe-4e8f-a12b-9cddb2560cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip3 install coremltools==5.0b5 protobuf==3.20.1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f470cdf-a29e-49d0-86ef-1c7d43e0e426",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## This code will print out the real, then expected for every batch of 32 \n",
    "# for batch in loader:\n",
    "#     batchX = batch[0]\n",
    "#     batchY = batch[1]\n",
    "#     print(batchY)\n",
    "#     print(net(batchX))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353da735-85b9-40f8-894c-74f3cb249cb5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Quantize and convert to TorchScript\n",
    "The process of tracing takes an example input and traces its flow through the model. You can trace the model by creating an example image input, as shown in the above code using random data. To understand the reasons for tracing and how to trace a PyTorch model, see Model Tracing.\n",
    "\n",
    "\n",
    "If your model uses a data-dependent control flow, such as a loop or conditional, the traced model won't generalize to other inputs. In such cases you can experiment with applying PyTorch's JIT script (torch.jit.script) to your model as described in Model Scripting. You can also use a combination of tracing and scripting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1fb4f44-86e6-4b7d-8778-640f08fb6681",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_dynamic_quantized = torch.quantization.quantize_dynamic(\n",
    "    net, qconfig_spec={torch.nn.Linear}, dtype=torch.qint8\n",
    ")\n",
    "# set model to evaluation mode\n",
    "model_dynamic_quantized.eval()\n",
    "example_tensor = weather_tensor[0,:-1]\n",
    "# convert to torch script\n",
    "traced_script_module = torch.jit.trace(net, example_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f27c530-19b8-4f53-900d-5f3718a9c4c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out = traced_script_module(example_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0625cff-ca20-4220-9e2a-aec018f6e3d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Convert to CoreML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfb35e82-9867-4ad7-b795-9e4923fca018",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting PyTorch Frontend ==> MIL Ops:  92%|▉| 12/13 [00:00<\n",
      "Running MIL Common passes:   0%|  | 0/40 [00:00<?, ? passes/s]/Users/lena/opt/anaconda3/envs/sunproject/lib/python3.9/site-packages/coremltools/converters/mil/mil/passes/name_sanitization_utils.py:107: UserWarning: Input, 'input.1', of the source model, has been renamed to 'input_1' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/lena/opt/anaconda3/envs/sunproject/lib/python3.9/site-packages/coremltools/converters/mil/mil/passes/name_sanitization_utils.py:135: UserWarning: Output, '26', of the source model, has been renamed to 'var_26' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "Running MIL Common passes: 100%|█| 40/40 [00:00<00:00, 3186.80\n",
      "Running MIL Clean up passes: 100%|█| 11/11 [00:00<00:00, 3556.\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|█| 18/18 [00:00<00\n"
     ]
    }
   ],
   "source": [
    "import coremltools as ct\n",
    "traced_script_module.eval()\n",
    "# Using image_input in the inputs parameter:\n",
    "# Convert to Core ML program using the Unified Conversion API.\n",
    "model = ct.convert(\n",
    "    traced_script_module,\n",
    "    inputs=[ct.TensorType(shape=example_tensor.shape)]\n",
    " )\n",
    "\n",
    "# Save the converted model.\n",
    "model.save(\"newmodel.mlmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8307002c-afb1-470b-9e34-7e617a99d54e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef00261e-3dc8-42a8-91ca-581e966dbee6",
   "metadata": {},
   "source": [
    "### Convert to CoreML Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62d0cf4a-0aea-4352-8dda-17875d0eacaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting PyTorch Frontend ==> MIL Ops:  92%|▉| 12/13 [00:00<\n",
      "Running MIL Common passes: 100%|█| 40/40 [00:00<00:00, 5406.08\n",
      "Running MIL FP16ComputePrecision pass: 100%|█| 1/1 [00:00<00:0\n",
      "Running MIL Clean up passes: 100%|█| 11/11 [00:00<00:00, 1362.\n"
     ]
    }
   ],
   "source": [
    "import coremltools as ct\n",
    "traced_script_module.eval()\n",
    "# Using image_input in the inputs parameter:\n",
    "# Convert to Core ML program using the Unified Conversion API.\n",
    "model = ct.convert(\n",
    "    traced_script_module,\n",
    "    convert_to=\"mlprogram\",\n",
    "    inputs=[ct.TensorType(shape=example_tensor.shape)]\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a592fb9-7632-4f79-968c-2d6611a24fee",
   "metadata": {},
   "source": [
    "got this message: \n",
    "\n",
    "Model is not in eval mode. Consider calling '.eval()' on your model prior to conversion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfacc56d-ea9c-4aa5-8425-25a4a8243816",
   "metadata": {
    "tags": []
   },
   "source": [
    "ALSO: \n",
    "As an alternative, you can convert the model to a neural network by eliminating the convert_to parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be88aac8-0524-4eb3-ae71-3660e5f39e32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the converted model.\n",
    "model.save(\"newmodel.mlpackage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f916b31-6c53-4daf-a152-f5ffb9f3cbbd",
   "metadata": {},
   "source": [
    "### success! (maybe?)\n",
    "next step is to try integrating it into my app:\n",
    "https://developer.apple.com/documentation/coreml/integrating_a_core_ml_model_into_your_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71463532-8a8d-4d31-a7a9-584552ec6f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ed615f-05db-4479-91f0-b7435efc2db8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c970ad54-6eb1-4e6b-addc-285bc36d1864",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952b8f8d-1e4c-4139-87e0-ae24aa486f98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65dfe32-659c-432d-9f8f-cee9b7e9c8a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8df99f5-95af-4b47-9ca0-3569b4b32ae7",
   "metadata": {},
   "source": [
    "The convert to ml code yields this attribute error: \n",
    "\n",
    "AttributeError: module 'numpy' has no attribute 'bool'.\n",
    "`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
    "The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n",
    "    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
    "    \n",
    "    \n",
    "trying to downgrade numpy: \n",
    "conda install -c conda-forge numpy=1.19.5 \n",
    "(a 2020 version)\n",
    "\n",
    "--> didnʻt work in my terminal. \n",
    "\n",
    "trying uninstall numpy\n",
    "--> worked\n",
    "\n",
    "conda install numpy=1.19.5  \n",
    "\n",
    "--> doesnt work because my python version is too high \n",
    "\n",
    "Specifications:\n",
    "\n",
    "  - numpy=1.19.5 -> python[version='3.6.*|3.7.*|3.9.*|3.8.*']\n",
    "  - numpy=1.19.5 -> python[version='>=3.6,<3.7.0a0|>=3.7,<3.8.0a0|>=3.8,<3.9.0a0|>=3.9,<3.10.0a0']\n",
    "\n",
    "Your python: python=3.11 (need python 3.6-3.9)\n",
    "\n",
    "if this doesnt work, will try editing sourcecode locatlly to correct for the attribute error\n",
    "--> looks like that exists in too many places. \n",
    "\n",
    "next, I will try downgrading my python version. First, must fiugre out the minimum python requirement for other pytorch operations\n",
    "\n",
    "conda install python=3.9\n",
    "\n",
    "then \n",
    "\n",
    "conda install numpy=1.19.5  \n",
    "\n",
    "then will retry\n",
    "\n",
    "\n",
    "--> now it doesnʻt recognize import torch, so reinstalling pytorch\n",
    "\n",
    " conda install pytorch torchvision torchaudio -c pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6202f8ec-0cbd-4f90-b84f-9dc913a59cbd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Optimize for pytorch model (old code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d7495b8-aae8-4a2a-b86b-330597006fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "# # optimize for mobile so that we can export and use in Swift app\n",
    "# torchscript_model_optimized = optimize_for_mobile(traced_script_module)\n",
    "\n",
    "# # save as .pt \n",
    "# path = os.path.join(os.getcwd(),\"model.pt\")\n",
    "# torchscript_model_optimized._save_for_lite_interpreter(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175ac7b3-8403-4bcb-8d6a-6107cd6e4f1b",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f248b69a-aff7-4745-b10c-edfc05d6847d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.9000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = weather_tensor[0,:-1]\n",
    "label = weather_tensor[0,-1]\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f275ce8a-3b7f-4de7-915c-86c5be6252ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9.4963], grad_fn=<AddBackward0>)\n",
      "tensor([2.4008e+02, 1.2300e+01, 2.0900e+01, 4.5000e+00, 1.5500e+01, 9.0000e-01,\n",
      "        8.4400e+01, 6.0000e-01, 1.0000e-01, 2.3000e+01, 0.0000e+00, 1.0143e+03,\n",
      "        0.0000e+00])\n"
     ]
    }
   ],
   "source": [
    "print(net(test))\n",
    "\n",
    "# net([2.4008e+02, 1.2300e+01, 2.0900e+01, 4.5000e+00, 1.5500e+01, 9.0000e-01,\n",
    "#         8.4400e+01, 6.0000e-01, 1.0000e-01, 2.3000e+01, 0.0000e+00, 1.0143e+03,\n",
    "#         0.0000e+00])\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2052d8b-24a2-499e-a1e8-54b4ef1b9d24",
   "metadata": {},
   "source": [
    "NOTES FROM CORY: HOW TO SPLIT UP training, validation, testing\n",
    "\n",
    "def train(loader):\n",
    "    one tound of training with all data in the loader\n",
    "    \n",
    "    \n",
    "def eval(loader):\n",
    "    feed evyerhting in batches to model, adds up and takes the losses of the batches\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756e79aa-7681-4b25-aabc-ff03e400ea9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
