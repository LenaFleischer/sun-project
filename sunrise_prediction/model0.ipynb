{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e883aeb-2d05-4ab3-bf99-dc438c57e45e",
   "metadata": {},
   "source": [
    "### Sunrise model\n",
    "based on a labeled weather dataset, predict whether the next sunrise will be beautiful\n",
    "- takes in weather vector for entire day for 365 days in COS AND label of good or bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0a4c2de-fa80-492f-80e3-a596d53c09ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lena/opt/anaconda3/envs/sunproject/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# dependencies: python 3.9, numpy 1.19.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e401610-e7e0-455c-a01a-bb66cf3a7af4",
   "metadata": {},
   "source": [
    "- load in weather data using only valid columns, leaving out the last column (wind chill label)\n",
    "- create a tensor from all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "538e3a05-f287-424b-8e03-1b38b85cd29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"prepped_data_1.csv\"\n",
    "weather_data = np.genfromtxt(input_path,delimiter = \",\", skip_header = 1, filling_values=0.0)\n",
    "weather_tensor = torch.tensor(weather_data).float()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb572fa-3308-4f6e-a973-518623fd31a6",
   "metadata": {},
   "source": [
    "read in as a tensor dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b411716b-f45b-4dd5-83b7-ff09fad7e454",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get labels from the sunrise, sunset columns\n",
    "\n",
    "sunrise_labels = weather_tensor[:, -2]\n",
    "sunset_labels = weather_tensor[:, -1]\n",
    "\n",
    "data = weather_tensor[:,:-2] # all weather data except sunrise and sunset labels\n",
    "\n",
    "weather_dataset = torch.utils.data.TensorDataset(data, sunrise_labels)\n",
    "# number of columns (minus the labels columns)\n",
    "xdims = weather_tensor.shape[1] - 2\n",
    "# number of rows \n",
    "ydims = weather_tensor.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9693a99-633c-4451-9c63-a191854cdd7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a4ae514-461a-4bc0-90a5-d3b9ca47656d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate mean and std and do the normalization by hand \n",
    "m = torch.mean(data, dim = 0)\n",
    "s = torch.std(data, dim = 0)\n",
    "\n",
    "norm_data = (data - m)/s\n",
    "\n",
    "norm_data\n",
    "\n",
    "m = m.detach().numpy().tolist()\n",
    "s = s.detach().numpy().tolist()\n",
    "\n",
    "import json\n",
    "\n",
    "mean = json.dumps(m)\n",
    "std = json.dumps(s)\n",
    "\n",
    "\n",
    "with open('mean.json', 'w') as f:\n",
    "    f.write(mean)\n",
    "with open('std.json', 'w') as f:\n",
    "    f.write(std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5b1d70-e950-428d-bdbd-ef5b2a22c887",
   "metadata": {},
   "source": [
    "DataLoader \n",
    "puts data on the right device, shuffles, can use parallel programming, define batch size etc\n",
    "- sees everything in an epoch\n",
    "- next epoch, sees them in a different order\n",
    "- suffles with 32 irows in a batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6de71f8a-05a3-4e19-a9a4-f4ba504270a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(weather_dataset, shuffle=True, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39b23c8f-3eca-446b-8552-f8e356af67da",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(xdims, 32), # takes in x dims columns, then funnels to a hidden layer of 32\n",
    "    torch.nn.ELU(), \n",
    "    # ELU is an activation layer, like a sigmoidal function!\n",
    "    torch.nn.Linear(32, 32),\n",
    "    torch.nn.ELU(),\n",
    "    torch.nn.Linear(32, 16),\n",
    "    torch.nn.ELU(),\n",
    "    torch.nn.Linear(16, 1)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be37741a-cc84-4a16-9ce6-22ca49ec2f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean squared error loss function\n",
    "criterion = torch.nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53e282f5-1a01-443e-9165-3636340cd247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer called Adam, using a learning rate of 1e-4\n",
    "opt = torch.optim.Adam(net.parameters(), 1e-4 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb0eda7-d98d-4a91-931a-34fa1a40e8db",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f373687-a0f6-4876-9bdb-93eeb08e8205",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lena/opt/anaconda3/envs/sunproject/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/lena/opt/anaconda3/envs/sunproject/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch 0\n",
      "tensor(472.6337, grad_fn=<AddBackward0>)\n",
      "--- epoch 30\n",
      "tensor(403.9732, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(pred, batchY)\n\u001b[1;32m     16\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 17\u001b[0m     \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ep\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m30\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sunproject/lib/python3.9/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sunproject/lib/python3.9/site-packages/torch/optim/optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sunproject/lib/python3.9/site-packages/torch/optim/adam.py:234\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    232\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 234\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m         \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sunproject/lib/python3.9/site-packages/torch/optim/adam.py:300\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 300\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sunproject/lib/python3.9/site-packages/torch/optim/adam.py:363\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    360\u001b[0m     param \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_real(param)\n\u001b[1;32m    362\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for ep in range(1000):\n",
    "    # every epoch sees every row exactly one time, but inputs are shuffled every epoch\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    # batch by batch\n",
    "    for batch in loader:\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        \n",
    "        batchX = batch[0]\n",
    "        batchY = batch[1]\n",
    "\n",
    "        pred = net(batchX)\n",
    "        loss = criterion(pred, batchY)\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss\n",
    "    if ep%30 == 0: \n",
    "        print(\"--- epoch \" + str(ep))\n",
    "        print(total_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f63659-8baa-441c-9869-9436155d7aed",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc13d0a-9ad6-4c17-aaf6-0df2879b2ba2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import random \n",
    "# row = random.randint(0, 365)\n",
    "# test = weather_tensor[row,:]\n",
    "# label = sunrise_labels[row]\n",
    "# print(\"Real Value:\")\n",
    "# print(label)\n",
    "# print(\"Predicted Value:\")\n",
    "# print(net(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9d7ed24d-35fe-4e8f-a12b-9cddb2560cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip3 install coremltools==5.0b5 protobuf==3.20.1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4f470cdf-a29e-49d0-86ef-1c7d43e0e426",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## This code will print out the real, then expected for every batch of 32 \n",
    "# for batch in loader:\n",
    "#     batchX = batch[0]\n",
    "#     batchY = batch[1]\n",
    "#     print(batchY)\n",
    "#     print(net(batchX))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353da735-85b9-40f8-894c-74f3cb249cb5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Quantize and convert to TorchScript\n",
    "The process of tracing takes an example input and traces its flow through the model. You can trace the model by creating an example image input, as shown in the above code using random data. To understand the reasons for tracing and how to trace a PyTorch model, see Model Tracing.\n",
    "\n",
    "\n",
    "If your model uses a data-dependent control flow, such as a loop or conditional, the traced model won't generalize to other inputs. In such cases you can experiment with applying PyTorch's JIT script (torch.jit.script) to your model as described in Model Scripting. You can also use a combination of tracing and scripting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1fb4f44-86e6-4b7d-8778-640f08fb6681",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_dynamic_quantized = torch.quantization.quantize_dynamic(\n",
    "    net, qconfig_spec={torch.nn.Linear}, dtype=torch.qint8\n",
    ")\n",
    "# set model to evaluation mode\n",
    "model_dynamic_quantized.eval()\n",
    "example_tensor = weather_tensor[0,:-1]\n",
    "# convert to torch script\n",
    "traced_script_module = torch.jit.trace(net, example_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f27c530-19b8-4f53-900d-5f3718a9c4c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out = traced_script_module(example_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef00261e-3dc8-42a8-91ca-581e966dbee6",
   "metadata": {},
   "source": [
    "### Convert to CoreML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62d0cf4a-0aea-4352-8dda-17875d0eacaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model is not in eval mode. Consider calling '.eval()' on your model prior to conversion\n",
      "Converting PyTorch Frontend ==> MIL Ops:  92%|████████████████████████████████████████████▎   | 12/13 [00:00<00:00, 2119.41 ops/s]\n",
      "Running MIL Common passes:   0%|                                                                      | 0/40 [00:00<?, ? passes/s]/Users/lena/opt/anaconda3/envs/sunproject/lib/python3.9/site-packages/coremltools/converters/mil/mil/passes/name_sanitization_utils.py:107: UserWarning: Input, 'input.1', of the source model, has been renamed to 'input_1' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/lena/opt/anaconda3/envs/sunproject/lib/python3.9/site-packages/coremltools/converters/mil/mil/passes/name_sanitization_utils.py:135: UserWarning: Output, '26', of the source model, has been renamed to 'var_26' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "Running MIL Common passes: 100%|███████████████████████████████████████████████████████████| 40/40 [00:00<00:00, 2259.13 passes/s]\n",
      "Running MIL FP16ComputePrecision pass: 100%|███████████████████████████████████████████████████| 1/1 [00:00<00:00, 97.78 passes/s]\n",
      "Running MIL Clean up passes: 100%|█████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 1279.35 passes/s]\n"
     ]
    }
   ],
   "source": [
    "import coremltools as ct\n",
    "\n",
    "# Using image_input in the inputs parameter:\n",
    "# Convert to Core ML program using the Unified Conversion API.\n",
    "model = ct.convert(\n",
    "    traced_script_module,\n",
    "    convert_to=\"mlprogram\",\n",
    "    inputs=[ct.TensorType(shape=example_tensor.shape)]\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a592fb9-7632-4f79-968c-2d6611a24fee",
   "metadata": {},
   "source": [
    "got this message: \n",
    "\n",
    "Model is not in eval mode. Consider calling '.eval()' on your model prior to conversion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfacc56d-ea9c-4aa5-8425-25a4a8243816",
   "metadata": {
    "tags": []
   },
   "source": [
    "ALSO: \n",
    "As an alternative, you can convert the model to a neural network by eliminating the convert_to parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be88aac8-0524-4eb3-ae71-3660e5f39e32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the converted model.\n",
    "model.save(\"newmodel.mlpackage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f916b31-6c53-4daf-a152-f5ffb9f3cbbd",
   "metadata": {},
   "source": [
    "### success! (maybe?)\n",
    "next step is to try integrating it into my app:\n",
    "https://developer.apple.com/documentation/coreml/integrating_a_core_ml_model_into_your_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71463532-8a8d-4d31-a7a9-584552ec6f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ed615f-05db-4479-91f0-b7435efc2db8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c970ad54-6eb1-4e6b-addc-285bc36d1864",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952b8f8d-1e4c-4139-87e0-ae24aa486f98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65dfe32-659c-432d-9f8f-cee9b7e9c8a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6202f8ec-0cbd-4f90-b84f-9dc913a59cbd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Optimize for pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7495b8-aae8-4a2a-b86b-330597006fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "# # optimize for mobile so that we can export and use in Swift app\n",
    "# torchscript_model_optimized = optimize_for_mobile(traced_script_module)\n",
    "\n",
    "# # save as .pt \n",
    "# path = os.path.join(os.getcwd(),\"model.pt\")\n",
    "# torchscript_model_optimized._save_for_lite_interpreter(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175ac7b3-8403-4bcb-8d6a-6107cd6e4f1b",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f248b69a-aff7-4745-b10c-edfc05d6847d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = 36\n",
    "test = weather_tensor[row,:]\n",
    "label = labels[row]\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f275ce8a-3b7f-4de7-915c-86c5be6252ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8277], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2052d8b-24a2-499e-a1e8-54b4ef1b9d24",
   "metadata": {},
   "source": [
    "NOTES FROM CORY: HOW TO SPLIT UP training, validation, testing\n",
    "\n",
    "def train(loader):\n",
    "    one tound of training with all data in the loader\n",
    "    \n",
    "    \n",
    "def eval(loader):\n",
    "    feed evyerhting in batches to model, adds up and takes the losses of the batches\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756e79aa-7681-4b25-aabc-ff03e400ea9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "50e49cc7-0346-44f9-b8fb-298dbc4ff859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a batch norm layer\n",
    "# bn = torch.nn.BatchNorm1d(num_features = xdims)\n",
    "# # normalize \n",
    "# data = bn(data) # how to extract the std and mean \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f06dc94-e442-4a6f-8da3-344507b3c876",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
